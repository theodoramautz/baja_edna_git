---
title: "phyloseq_tutorial"
output: html_document
date: "2024-03-07"
---

```{r phyloseq setup}
library(phyloseq); packageVersion("phyloseq")
library(Biostrings); packageVersion("Biostrings")
library(ggplot2); packageVersion("ggplot2")
library(tidyverse)
library(here)
library(dplyr)

# Set plot theme to a simple black-and-white design
theme_set(theme_bw())
```

```{r phyloseq preprocessing}
# Import your output ASV table from DADA2 (wide format). 
asvs <- read.csv(here("data", "sequencing_data", "Baja_MiFish_ASVs_wide.csv"),row.names=1)

# Import your taxonomy table and hash key. We will merge these two files to generate a taxonomy table formatted for phyloseq.
tax <- read.csv (here("data", "sequencing_data", "Baja_MiFish_taxa_table.csv"))
hash <- read.csv(here("data", "sequencing_data","Baja_MiFish_hash_key.csv"))

# Import the metadata file. Before importing, make sure the order of your samples in the ASV table matches the order in the metadata table. You can check this in Excel before importing or you can filter tables and edit row names in R, whichever you prefer. I will provide an example of how to do it in R.
metadata <- read.csv(here("data", "baja_edna_metadata.csv"), row.names=1)
```

```{r phyloseq format}
# Format the ASV and tax tables for phyloseq

# In this case each ASV (taxon) is a row
ASV = otu_table(asvs, taxa_are_rows=TRUE)

# For phyloseq taxonomy, we need to merge the tax and hash tables so that we have a list of hashes with associated taxonomy. 

# First we have to rename the column in the taxonomy table containing the nucleotide sequences.
# tax <- rename(tax, 'Sequence' = 'X')

# Now we can merge on the 'Sequence' column and then drop it from the merged data frame
tax_ps <- left_join(hash, tax, by='Sequence')
tax_ps <- select(tax_ps, -Sequence)

# Convert the hashes to row names and convert the whole data frame to a matrix
rownames(tax_ps) <- tax_ps$Hash
tax_ps <- select(tax_ps, -Hash)
tax_ps_mat <- as.matrix(tax_ps)

# Convert the taxonmy table into phyloseq format
TAX <- tax_table(tax_ps_mat)
```

```{r metadata}
# The Baja metadata row names are the same as the ASV table column names, so we don't need to do any name editing!

# If you removed any samples during DADA2 processing, they need to be removed from the metadata file too

# Check the number of samples in the ASV table
length(colnames(asvs))

# Check the number of samples in the metadata table
length(rownames(metadata))

# They are the same! You can take a closer look at the actual names and make sure they are identical if you're concerned, otherwise move on to the next step (line 78).

# IF THE TWO NUMBERS ABOVE ARE DIFFERENT: the next section will edit the metadata so it only includes samples we have in the ASV table.
```

```{r filter metadata}
# Make a list of the names we want to keep
samples.to.keep <- colnames(asvs)

metadata.filt <-filter(metadata, row.names(metadata) %in%
                                     samples.to.keep)

# Check again that the number of metadata rows matches the number of ASV table columns
length(colnames(asvs))
length(rownames(metadata.filt))

# Convert the metadata table into phyloseq format (use "metadata.filt" instead of "metadata" if you filtered out metadata rows)
MET <- sample_data(metadata)
```

```{r phyloseq prep}
# Make the phyloseq object from the ASV table, taxonomy table, and metadata table
ps <- phyloseq(ASV, MET, TAX)

# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))

# The sample_data has sample names as rownames, but we can add a column with the names as well
sample_data(ps.prop)['sample.id'] <-
  row.names(sample_data(ps.prop))
```

```{r sample summary}
# Generate some basic read stats: mean, max and min of sample read counts
smin <- min(sample_sums(ps))
smean <- mean(sample_sums(ps))
smax <- max(sample_sums(ps))

# You can check these values at any time by just typing, for example, 'smin' into the console

## Now let's get an overview of the read distribution across samples using a histogram made by ggplot

# First make a data frame with a column for the read counts of each sample
sample_sum_df <- data.frame(sum = sample_sums(ps))

# Histogram of sample read counts
p <- ggplot(sample_sum_df, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "indianred", binwidth = 2000) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  ylab("Number of samples") +
  scale_y_continuous(limits = c(0, 12), expand = c(0,0)) +
  scale_x_continuous(limits = c(0, 400000), expand = c(0,0))

p

# NOTE: You may get a warning message saying 5 rows of data were removed due to missing values. This is a misleading warning message, none of the data were removed and this plot shows all the sample counts.
```

```{r phyloseq bar plots}
# Here I am grouping (arbitrarily) by season
top20 <- names(sort(taxa_sums(ps.prop),
                    decreasing=TRUE))[1:20]

ps.top20 <- prune_taxa(top20, ps.prop)

bar <- plot_bar(ps.top20, x="Site_ID", fill="Family") +
  facet_wrap(~lat_group, scales="free_x")

bar

# Uh oh, looks like we have some non-fish families in here! Try to filter out these taxa and re-run the analyses. You may have to re-filter samples as well.
```

```{r phyloseq filtertax}
# Let's filter out the two obvious contaminant families
# I can't find a way to do this in one step, bonus points if you can!
ps.prop.pruned <- subset_taxa(ps.prop,
                                Family != "Bovidae")
ps.prop.pruned <- subset_taxa(ps.prop.pruned,
                                Family != "Hominidae")

# You may have empty samples after removing the contaminants. Remove those empty samples from the data set.
ps.prop.pruned.v2 <- prune_samples(sample_sums(ps.prop.pruned)>0, 
                                   ps.prop.pruned)

top20 <- names(sort(taxa_sums(ps.prop.pruned.v2),
                    decreasing=TRUE))[1:20]

ps.top20 <- prune_taxa(top20, ps.prop.pruned.v2)

bar2 <- plot_bar(ps.top20, x="Site_ID", fill="Family") +
  facet_wrap(~lat_group, scales="free_x")

bar2
```
Now we can run some basic diversity analyses

```{r alpha diversity}
# Plot alpha diversity metrics
alpha <- plot_richness(ps.prop.pruned.v2, 
              x="lat_group", 
              measures=c("Shannon", "Simpson"), 
              color="lat_group")
alpha
```

```{r phyloseq beta diversity}
# Plot beta diversity in NMDS

# Generate the ordinations using the Bray-Curtis distance metric
ord.nmds.bray <- ordinate(ps.prop.pruned.v2, "NMDS", "bray")

# Plot!

p1 <- plot_ordination(ps.prop.pruned.v2, 
                      ord.nmds.bray, 
                      color="lat_group", 
                      title="Bray NMDS",
                      label="sample.id")
p1
```

# You may be interested in investigating specific samples if they look like outliers

```{r outliers}
# To explore the phyloseq we can convert the object components to data frames
asv <- data.frame(otu_table(ps.prop.pruned.v2))
tax <- data.frame(tax_table(ps.prop.pruned.v2))
sd <- data.frame(sample_data(ps.prop.pruned.v2))

# Using the "ASV" data frame let's look at FISH_125
BAJA_125 <- subset(asv, ,"BAJA_125")
max(BAJA_125$BAJA_125)

# Almost all (94%) of the ASVs belong to the ASV with the hash "303ab366b448fc492f429b0b17e4edf1219c7707". What is the taxonomy of that ASV?

tax_hash <- tax_ps %>% 
  filter(row.names(tax_ps) %in%
           "303ab366b448fc492f429b0b17e4edf1219c7707")

# This ASV belongs to a mackerel! It does not appear to be contamination, just a sample unusually dominated by oen species. We can leave it as a legitimate sample for other analyses.
```

We can also run a different type of ordination: principal coordinate analysis

```{r PCoA}
# Ordinate
ord.pcoa.bray.pruned.v2 <- ordinate(ps.prop.pruned.v2,
                                    method="PCoA",
                                    distance="bray"
)

# Plot
pcoa <- plot_ordination(ps.prop.pruned.v2,
                        ord.pcoa.bray.pruned.v2,
                        color="Site_ID",
                        shape="lat_group",
                        title="PCoA of Baja MiFish samples") +
  theme_classic()
```

What are the similarities and differences between the two types of ordination plots you made? Try grouping by different variables (chlorophyll, oxygen, etc.) and see what happens

You can find more examples of ordination in phyloseq here: https://joey711.github.io/phyloseq/plot_ordination-examples.html

So far all of these analyses have been "exploratory," i.e. they have no statistical power behind them. Now that we have a sense of potential patterns (or lack thereof) we can test these hypotheses with post-hoc tests. The most relevant test for these type of data is a PERMANOVA, or Permutational Analysis of Variance. You should definitely learn more about ANOVAs and PERMANOVAs when you get the chance!

```{r permanova}
# First we will need a new library: vegan!
library(vegan)

# Extract the distance matrix (same one we used for the PCoA)
dist <- phyloseq::distance(ps.prop.pruned.v2, "bray")

ps.perm.data <- data.frame(sample_data(ps.prop.pruned.v2))

# Test for the significance of season on sample distances
permanova <- adonis2(dist ~ lat_group,
                     ps.perm.data,
                     permutations=999)
permanova

# We can also test multiple variables in a multifactorial PERMANOVA
# This example uses a made-up metadata group, "Temp_group_C", that will not work (unless you add it to the metadata!)
permanova.v2 <- adonis2(dist ~ lat_group * Most_Common_Habitat,
                     ps.perm.data,
                     permutations=999)
permanova.v2
```

```{r normalize}
# There are many ways to normalize and/or standardize eDNA read counts. In this tutorial we just converted counts to relative abundance; here are a few other methods. These lines could each individually replace line 90. Please look them up and think about why we might want to use them!

# Hellinger transformation
# vegan equivalent: decostand
ps.hell <- transform_sample_counts(ps, function(x) sqrt(x / sum(x)))

# Wisconsin Double standardization
# This is not a built-in function for phyloseq, so we have to do it to the ASV table and then re-import it to a phyloseq object
# First we need to filter out our contaminants from our original (unstandardized!) phyloseq table
ps.pruned <- subset_taxa(ps, Family != "Bovidae")
ps.pruned <- subset_taxa(ps.pruned, Family != "Hominidae")
ps.pruned.v2 <- prune_samples(sample_sums(ps.pruned)>0, 
                                   ps.pruned)
asv <- data.frame(otu_table(ps.pruned.v2))

asv.wisc <- decostand(asv, method = "total", MARGIN = 2)

ps.wisc <- phyloseq(ASV, MET, TAX)

# Now you can go back and use ps.hell or ps.wisc in place of ps.prop.pruned.v2 for the alpha beta diversity plots!

# Can you find other standardization/normalization methods we might want to test?
```
